# AI Optimization #

## Overview ## 
The goal of this repository is to help AI developpers to design more efficient neural network models. The techniques in this repository are not suited for fine-tuning existing models, but rather for helping to create more efficient models from an chosen type of architecture.
This repository is divided in several chapters, each focusing on one category of optimization. 

## 1. Parameters reduction ## 

The goal of this repository is to optimize models that will be implemented in edge devices with limited memory (sensors, cameras, smartphones, ...). Therefore, it is of significant importance to reduce the number of parameters of such models. Seveveral parameters-count reducing techniques are displayed and benchmarked there.

## 2. Inference acceleration ##

In this repository, I will focus on method to accelerate the inference speed of a model. A faster inference guarantees a faster, therefore cheaper, training, as well as a better experience for the final users of the model. Some methods in this repository may be similar to their counterpart in the parameters reduction chapter, but the benchmarks are different.